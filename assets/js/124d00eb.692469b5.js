"use strict";(self.webpackChunkanomstack=self.webpackChunkanomstack||[]).push([[5639],{2072:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>r,contentTitle:()=>o,default:()=>u,frontMatter:()=>a,metadata:()=>i,toc:()=>d});const i=JSON.parse('{"id":"features/llm-agent","title":"LLM Agent","description":"The LLM (Large Language Model) agent in Anomstack provides AI-powered anomaly detection using the anomaly-agent library. It analyzes time series data using multimodal LLMs to identify anomalies with natural language explanations.","source":"@site/docs/features/llm-agent.md","sourceDirName":"features","slug":"/features/llm-agent","permalink":"/anomstack/docs/features/llm-agent","draft":false,"unlisted":false,"editUrl":"https://github.com/andrewm4894/anomstack/tree/main/docs/docs/features/llm-agent.md","tags":[],"version":"current","sidebarPosition":5,"frontMatter":{"sidebar_position":5},"sidebar":"docsSidebar","previous":{"title":"Dashboard","permalink":"/anomstack/docs/features/dashboard"},"next":{"title":"Data Sources","permalink":"/anomstack/docs/data-sources"}}');var s=t(4848),l=t(8453);const a={sidebar_position:5},o="LLM Agent",r={},d=[{value:"Features",id:"features",level:2},{value:"Configuration",id:"configuration",level:2},{value:"Multimodal Image Support",id:"multimodal-image-support",level:3},{value:"Custom Prompts",id:"custom-prompts",level:3},{value:"Environment Variables",id:"environment-variables",level:2},{value:"How It Works",id:"how-it-works",level:2},{value:"Integration with PostHog",id:"integration-with-posthog",level:2},{value:"Example Output",id:"example-output",level:2},{value:"Best Practices",id:"best-practices",level:2},{value:"Troubleshooting",id:"troubleshooting",level:2},{value:"LLM alerts not running",id:"llm-alerts-not-running",level:3},{value:"No anomalies detected",id:"no-anomalies-detected",level:3},{value:"High token usage",id:"high-token-usage",level:3}];function c(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,l.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.header,{children:(0,s.jsx)(n.h1,{id:"llm-agent",children:"LLM Agent"})}),"\n",(0,s.jsxs)(n.p,{children:["The LLM (Large Language Model) agent in Anomstack provides AI-powered anomaly detection using the ",(0,s.jsx)(n.a,{href:"https://github.com/andrewm4894/anomaly-agent",children:"anomaly-agent"})," library. It analyzes time series data using multimodal LLMs to identify anomalies with natural language explanations."]}),"\n",(0,s.jsx)(n.h2,{id:"features",children:"Features"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"LLM-Powered Detection"}),": Uses OpenAI models (gpt-4o-mini by default) for intelligent anomaly identification"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Multimodal Analysis"}),": Optionally includes time series plots for visual pattern recognition"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Two-Stage Pipeline"}),": Detection and verification phases to reduce false positives"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Natural Language Explanations"}),": Get human-readable descriptions of detected anomalies"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"PostHog Integration"}),": Automatic LLM analytics tracking when PostHog is configured"]}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"configuration",children:"Configuration"}),"\n",(0,s.jsxs)(n.p,{children:["Configure the LLM agent in your metric batch YAML or ",(0,s.jsx)(n.code,{children:"defaults.yaml"}),":"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-yaml",children:"# Enable LLM alerts for a metric batch\ndisable_llmalert: False\nllmalert_default_schedule_status: 'RUNNING'\n\n# LLM alert parameters\nllmalert_recent_n: 5                          # Number of recent observations to analyze\nllmalert_smooth_n: 0                          # Smoothing applied before analysis\nllmalert_metric_rounding: -1                  # Decimal places for rounding (-1 = no rounding)\nllmalert_metric_timestamp_max_days_ago: 30    # Max age of metrics to analyze\nllmalert_prompt_max_n: 1000                   # Max observations in prompt\nllmalert_include_plot: True                   # Include visual plot for multimodal analysis\nllmalert_cron_schedule: \"*/5 * * * *\"         # How often to run LLM analysis\n"})}),"\n",(0,s.jsx)(n.h3,{id:"multimodal-image-support",children:"Multimodal Image Support"}),"\n",(0,s.jsxs)(n.p,{children:["When ",(0,s.jsx)(n.code,{children:"llmalert_include_plot: True"})," (default), Anomstack generates a matplotlib visualization of the time series and sends it alongside the numeric data to the LLM. This enables:"]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Visual pattern recognition for trends, seasonality, and outliers"}),"\n",(0,s.jsx)(n.li,{children:"More context-aware anomaly descriptions"}),"\n",(0,s.jsx)(n.li,{children:"Better detection of patterns that may not be obvious in raw numbers"}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:"The plot is encoded as base64 PNG and works with any multimodal-capable model (gpt-4o-mini, gpt-4o, etc.)."}),"\n",(0,s.jsx)(n.h3,{id:"custom-prompts",children:"Custom Prompts"}),"\n",(0,s.jsx)(n.p,{children:"You can customize the detection and verification prompts:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-yaml",children:"llmalert_anomaly_agent_detection_prompt: |\n  You are an expert anomaly detection agent analyzing server metrics.\n  Focus on: CPU spikes, memory leaks, unusual network patterns.\n  Consider time of day and typical usage patterns.\n\nllmalert_anomaly_agent_verification_prompt: |\n  You are an expert anomaly verification agent.\n  Review detected anomalies and confirm only those that represent genuine issues.\n  Consider normal business operations and seasonality.\n"})}),"\n",(0,s.jsx)(n.h2,{id:"environment-variables",children:"Environment Variables"}),"\n",(0,s.jsx)(n.p,{children:"Required environment variables for LLM alerts:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"# Required: OpenAI API key\nOPENAI_API_KEY=your-openai-api-key\n\n# Optional: Model selection (defaults to gpt-4o-mini)\nANOMSTACK_OPENAI_MODEL=gpt-4o-mini\n\n# Optional: PostHog for LLM analytics tracking\nPOSTHOG_API_KEY=your-posthog-api-key\nPOSTHOG_ENABLED=true\n"})}),"\n",(0,s.jsx)(n.p,{children:"You can also override llmalert settings per metric batch:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"ANOMSTACK__MY_BATCH__LLMALERT_INCLUDE_PLOT=True\nANOMSTACK__MY_BATCH__DISABLE_LLMALERT=False\n"})}),"\n",(0,s.jsx)(n.h2,{id:"how-it-works",children:"How It Works"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Data Collection"}),": The ",(0,s.jsx)(n.code,{children:"llmalert_sql"})," query retrieves recent metric data"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Plot Generation"}),": If ",(0,s.jsx)(n.code,{children:"llmalert_include_plot=True"}),", a matplotlib plot is created"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"LLM Analysis"}),": Data (and optionally the plot) is sent to the anomaly-agent"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Detection"}),": The LLM identifies potential anomalies with descriptions"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Verification"})," (optional): A second LLM pass filters false positives"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Output"}),": Anomalies are logged and can trigger alerts"]}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"integration-with-posthog",children:"Integration with PostHog"}),"\n",(0,s.jsx)(n.p,{children:"When PostHog is configured, LLM calls are automatically tracked in PostHog's LLM Analytics:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Token usage and costs"}),"\n",(0,s.jsx)(n.li,{children:"Input/output content (including images when multimodal)"}),"\n",(0,s.jsx)(n.li,{children:"Latency metrics"}),"\n",(0,s.jsx)(n.li,{children:"Model information"}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:"This provides visibility into LLM usage across your anomaly detection pipeline."}),"\n",(0,s.jsx)(n.h2,{id:"example-output",children:"Example Output"}),"\n",(0,s.jsx)(n.p,{children:"When an anomaly is detected, you'll see output like:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"Detected anomaly in metric 'cpu_usage':\n  Timestamp: 2024-01-15 14:30:00\n  Value: 98.5\n  Description: Significant CPU spike to 98.5%, well above the normal\n  range of 20-40%. This appears to be a genuine anomaly that warrants\n  investigation, possibly indicating a runaway process or resource\n  exhaustion.\n"})}),"\n",(0,s.jsx)(n.h2,{id:"best-practices",children:"Best Practices"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Start with defaults"}),": The default settings work well for most use cases"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Enable multimodal"}),": Keep ",(0,s.jsx)(n.code,{children:"llmalert_include_plot: True"})," for better detection"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsxs)(n.strong,{children:["Tune ",(0,s.jsx)(n.code,{children:"llmalert_recent_n"})]}),": Adjust based on your metric frequency"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Custom prompts"}),": Use domain-specific prompts for specialized metrics"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Monitor costs"}),": Use PostHog to track LLM token usage and costs"]}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"troubleshooting",children:"Troubleshooting"}),"\n",(0,s.jsx)(n.h3,{id:"llm-alerts-not-running",children:"LLM alerts not running"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["Check ",(0,s.jsx)(n.code,{children:"disable_llmalert: False"})," in your config"]}),"\n",(0,s.jsxs)(n.li,{children:["Verify ",(0,s.jsx)(n.code,{children:"llmalert_default_schedule_status: 'RUNNING'"})]}),"\n",(0,s.jsxs)(n.li,{children:["Ensure ",(0,s.jsx)(n.code,{children:"OPENAI_API_KEY"})," is set"]}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"no-anomalies-detected",children:"No anomalies detected"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"The LLM may not find anomalies if data is normal"}),"\n",(0,s.jsxs)(n.li,{children:["Check ",(0,s.jsx)(n.code,{children:"llmalert_recent_n"})," includes enough data points"]}),"\n",(0,s.jsx)(n.li,{children:"Review the data being sent with debug logging"}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"high-token-usage",children:"High token usage"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["Reduce ",(0,s.jsx)(n.code,{children:"llmalert_prompt_max_n"})," to limit data sent"]}),"\n",(0,s.jsxs)(n.li,{children:["Adjust ",(0,s.jsx)(n.code,{children:"llmalert_cron_schedule"})," to run less frequently"]}),"\n",(0,s.jsx)(n.li,{children:"Consider disabling verification for cost savings"}),"\n"]})]})}function u(e={}){const{wrapper:n}={...(0,l.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(c,{...e})}):c(e)}},8453:(e,n,t)=>{t.d(n,{R:()=>a,x:()=>o});var i=t(6540);const s={},l=i.createContext(s);function a(e){const n=i.useContext(l);return i.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:a(e.components),i.createElement(l.Provider,{value:n},e.children)}}}]);